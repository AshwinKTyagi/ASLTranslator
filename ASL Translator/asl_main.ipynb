{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d730be4-4683-4167-87e6-abaace0479b9",
   "metadata": {},
   "source": [
    "# Live Sign Language Translator\n",
    "Our goal is to create a program that will recognise sign language caught by video and translate it into it's English counterpart.\n",
    "#### Current Limitations:\n",
    "- Only recognises ASL Letters and not any words.\n",
    "- Dataset does not include J and Z since they require motion. Current workaround is to put a placeholder and try to guess the word while generating words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3bfc57-be6e-47c0-99a9-979eb484dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # data processing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from asl_dataset import SignLanguageDataset\n",
    "from asl_net import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b2324-cc26-4b39-891b-09506c1cf79d",
   "metadata": {},
   "source": [
    "## Initialize net from predefined Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715e96e4-d729-44c3-924e-b14b4cd87407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (fc1): Linear(in_features=400, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (leak): LeakyReLU(negative_slope=0.01)\n",
       "  (drop): Dropout(p=0.3, inplace=False)\n",
       "  (fc3): Linear(in_features=64, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net_path = \"sign_lang_net.pth\"\n",
    "\n",
    "net.load_state_dict(torch.load(net_path))\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e7a55-3977-4b21-8f64-566cecdc06e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11.6",
   "language": "python",
   "name": "python3.11.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
