{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9aPxMR8_ZTC"
   },
   "source": [
    "# Live Sign Language Translator\n",
    "Our goal is to create a program that will recognise sign language caught by video and translate it into it's English counterpart.\n",
    "####Current Limitations:\n",
    "- Only recognises ASL Letters and not any words.\n",
    "- Dataset does not include J and Z since they require motion. Current workaround is to put a placeholder and try to guess the word while generating words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5313,
     "status": "ok",
     "timestamp": 1662939811392,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "qI9bi4ktEhon"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # data processing\n",
    "import os, sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUgYHWi5Rg4W"
   },
   "source": [
    "#### Presetup before generating and training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1662939829071,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "ISg44OxXRhUK",
    "outputId": "5c4bc3fb-d367-438b-8dc1-8bb95f181da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "#set device so that the model and data will run on the correct graphics device\n",
    "dev = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4335,
     "status": "ok",
     "timestamp": 1662939833399,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "gVmCUni9Fe8V",
    "outputId": "c1b70f54-3576-42a8-b17c-95f4c3515daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=400, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (leak): LeakyReLU(negative_slope=0.01)\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        ''' init the nerual network '''\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, 3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*5*5, 100)\n",
    "        self.fc2 = nn.Linear(100, 64)\n",
    "        self.leak = nn.LeakyReLU()\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.fc3 = nn.Linear(64, 25)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''defines the forward prop algorithm'''\n",
    "        #apply Convolution on the relu'd results from the convolution layers\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = x.view((x.shape[0], -1))\n",
    "\n",
    "        #run the fcs\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.leak(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        #fc4 will give us the final **24** layers\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "#switch the nn to run on gpu if available\n",
    "net = net.to(dev)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REF9riJFQeTc"
   },
   "source": [
    "####Define the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1662939833400,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "ariGAOYLQaxe"
   },
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()\n",
    "#feel free to play around with the lr(learning rate) and momentum\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHKmAp5wTW3G"
   },
   "source": [
    "#### Set up Training Data\n",
    "Init and transform data before running it through nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1662939833915,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "1Eq11XX7TWX0",
    "outputId": "21b2def4-8002-4d5e-f81a-679b21160468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../kaggle/input/.DS_Store\n",
      "../kaggle/input/american_sign_language.PNG\n",
      "../kaggle/input/sign_mnist_test.csv\n",
      "../kaggle/input/sign_mnist_train.csv\n",
      "../kaggle/input/amer_sign3.png\n",
      "../kaggle/input/amer_sign2.png\n",
      "../kaggle/input/sign_mnist_train/sign_mnist_train.csv\n",
      "../kaggle/input/sign_mnist_test/sign_mnist_test.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('../kaggle/input/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4621,
     "status": "ok",
     "timestamp": 1662939838530,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "sG_UvNSpJSFU"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../kaggle/input/sign_mnist_train.csv')\n",
    "test = pd.read_csv('../kaggle/input/sign_mnist_test.csv')\n",
    "#Put in J as a _ to maintain 1to1 matching in nn\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', '_', 'K', 'L', 'M', \n",
    "          'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW7m8QfaLlKz"
   },
   "source": [
    "Create Class for Dataset to init and transform datasets\n",
    "I'm setting up the data similar to how Georgy Popov did in his nn on kaggle\n",
    "https://www.kaggle.com/code/wacholder000/simple-convolution-nn-in-pytorch-test-acc-95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1662939838531,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "VZcYy_7sLkmC"
   },
   "outputs": [],
   "source": [
    "class SignLanguageDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        '''init dataset'''\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''init return length of dataset'''\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''define label and transform image based on index given'''\n",
    "        label = self.df.iloc[index, 0]\n",
    "\n",
    "        img = self.df.iloc[index, 1:].values.reshape(28, 28)\n",
    "        img = torch.Tensor(img).unsqueeze(0)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1662939838532,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "LoDL8XmHJqsH"
   },
   "outputs": [],
   "source": [
    "#method for showing images using mathplt\n",
    "def show_img(img, label):\n",
    "    img = img.squeeze()\n",
    "    img = img*40. + 159.\n",
    "    imgnp = img.detach().numpy()\n",
    "    plt.imshow(img, interpolation='bicubic')\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1662939992647,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "kGL2Z1kHJq1N"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #randomly flip/rotate images to better train nn\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=(-180,180))],\n",
    "                           p = 0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1662939993860,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "Mt1qrrTULYEF"
   },
   "outputs": [],
   "source": [
    "train_dataset = SignLanguageDataset(train, transform=train_transform)\n",
    "test_dataset = SignLanguageDataset(test)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=100, shuffle=True,\n",
    "                               num_workers=2)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=100, shuffle=True,\n",
    "                              num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23Hd0lv6Nfzk"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1662939996059,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "SUbpPsPYNeOX",
    "outputId": "7e72f784-4f7a-41f2-976a-b482b9fe7446"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'SignLanguageDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m img, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(trainiter)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainiter = iter(train_loader)\n",
    "img, label = next(trainiter)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1662939997778,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "e-YAzGEROjAR",
    "outputId": "bda2163d-2d38-4541-b2aa-c7611ec3724d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m show_img(\u001b[43mimg\u001b[49m[\u001b[38;5;241m10\u001b[39m], label[\u001b[38;5;241m10\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "show_img(img[10], label[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwT4wWvIPHl-"
   },
   "source": [
    "#### Define Training and Eval\n",
    "Now that we have defined a simple conv2d nn and init all our training data, we can start work on defining our training and evaluation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1662940003382,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "1l9YIEUcOti4"
   },
   "outputs": [],
   "source": [
    "def eval_net(model, crit, test_loader):\n",
    "\n",
    "    #this will switch the net to run on gpu if supported and selected\n",
    "    #if there is no device chosen, default will be cpu\n",
    "    \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0.0\n",
    "    num_total = 0.0\n",
    "\n",
    "    for batch, labels in test_loader:\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        out = model(batch)\n",
    "        pred_labels = out.argmax(dim=1)\n",
    "        num_correct += float((pred_labels == labels).sum())\n",
    "\n",
    "        loss = crit(out, labels)\n",
    "        running_loss += loss.data.cpu()\n",
    "\n",
    "        num_total += labels.shape[0]\n",
    "\n",
    "    mean_loss = running_loss / num_total\n",
    "    accuracy = num_correct / num_total\n",
    "\n",
    "    return mean_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1662940003524,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "9sQVlDW4RG4T"
   },
   "outputs": [],
   "source": [
    "def train_model(n_epochs, model, optimizer, crit, train_loader,\n",
    "                test_loader):\n",
    "    \n",
    "    device = torch.device(\"mps\") if torch..is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    model = model.train()\n",
    "    \n",
    "    train_loss, train_acc = [], []\n",
    "    test_loss, test_acc = [], []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        t0 = time.perf_counter()\n",
    "        \n",
    "        running_loss = 0.\n",
    "        num_correct = 0.\n",
    "        num_total = 0.\n",
    "        \n",
    "        for batch, labels in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(batch)\n",
    "            \n",
    "            pred_labels = out.argmax(dim=1)\n",
    "            num_correct += float((pred_labels == labels).sum())\n",
    "            num_total += labels.shape[0]\n",
    "            \n",
    "            loss = crit(out, labels)\n",
    "            running_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss = running_loss / num_total\n",
    "        epoch_acc = num_correct / num_total\n",
    "        \n",
    "        train_loss.append(epoch_loss.data.cpu())\n",
    "        train_acc.append(epoch_acc)\n",
    "        \n",
    "        t_loss, t_acc = eval_net(model, crit, test_loader)\n",
    "        \n",
    "        test_loss.append(t_loss.data.cpu())\n",
    "        test_acc.append(t_acc)\n",
    "        \n",
    "        t1 = time.perf_counter()\n",
    "        \n",
    "        delta_t = t1 - t0\n",
    "        print(f\"EPOCH {epoch+1} ({round(delta_t, 4)} s.): train loss - {epoch_loss}, train accuracy - {epoch_acc}; test loss - {t_loss}, test accuracy - {t_acc}\")\n",
    "    \n",
    "    \n",
    "    return model, train_loss, train_acc, test_loss, test_acc        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc7bto2MsW0x"
   },
   "source": [
    "#### Run the train_model func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243817,
     "status": "ok",
     "timestamp": 1662940249329,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "O5wAnatORZUJ",
    "outputId": "901b6913-0535-4370-8d66-b8483257bd86"
   },
   "outputs": [],
   "source": [
    "net, train_loss, train_acc, test_loss, test_acc = train_model(20, net, optimizer, crit,\n",
    "                                                     train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1662940315719,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "IoMH1mfg8Ajw",
    "outputId": "3bf41fbb-db8f-4b15-9fba-559f5dc04194"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "ax1.plot(train_loss)\n",
    "ax1.plot(test_loss)\n",
    "ax1.legend(['train', 'test'])\n",
    "ax1.set_title('Loss')\n",
    "ax2.plot(train_acc)\n",
    "ax2.plot(test_acc)\n",
    "ax2.legend(['train', 'test'])\n",
    "ax2.set_title('Accuracy')\n",
    "\n",
    "print(\"Accuracy: %.3f, %.3f\" % (train_acc[19], test_acc[19]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZdW5PLM9_4q"
   },
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1662940329893,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "OVmZUKXi-F4G"
   },
   "outputs": [],
   "source": [
    "state = net.state_dict()\n",
    "\n",
    "torch.save(state, './sign_lang_net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIThSEj7-ZWc"
   },
   "source": [
    "#### Check Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1662940395644,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "kXV5je5I-Zzy"
   },
   "outputs": [],
   "source": [
    "testiter = iter(test_loader)\n",
    "img, label = next(testiter)\n",
    "net = net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1662940396371,
     "user": {
      "displayName": "Ashwin Tyagi",
      "userId": "01848559523199568635"
     },
     "user_tz": 420
    },
    "id": "IVcHB5CfAiHh",
    "outputId": "df94c234-d1ed-46b7-d06f-aa0eda8ea015"
   },
   "outputs": [],
   "source": [
    "image = img[0]\n",
    "lab = label[0]\n",
    "\n",
    "batch = train_transform(image).unsqueeze(0)\n",
    "# if you want to run a single img through the nn do this\n",
    "pred = net(batch).squeeze(0).softmax(0)\n",
    "class_id = pred.argmax().item()\n",
    "#class_id will give the most likely index.\n",
    "#Ex: if class_id is 7 -> that means the expected value would be labels[7] or H\n",
    "\n",
    "_, indicies = torch.sort(pred, descending=True)\n",
    "    \n",
    "for ind in indicies[:5]:\n",
    "    i = ind.item()\n",
    "    print(f\"{labels[i]}: {100.*pred[i]:.2f}%\")\n",
    "\n",
    "print(f\"Correct: {labels[lab]}\")\n",
    "\n",
    "show_img(batch, lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5n__5EW39-H-"
   },
   "source": [
    "# New Section"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "IwT4wWvIPHl-",
    "1ZdW5PLM9_4q"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "python3.11.6",
   "language": "python",
   "name": "python3.11.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
